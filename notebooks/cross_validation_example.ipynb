{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation and Scikit-Learn Model Template\n",
    "\n",
    "Cross-validation is a technique that uses the training data, for which we have outcome labels, to estimate the performance and bias of a classifier.  It is commonly called *k*-fold cross-validation (*k*-fold CV), since we partition the training data into *k* groups.  We then leave one of those groups out for testing data, train the model on the remaining groups, and test on the left out group to get an estimate of performance.  The performance is then averaged across all **folds** (groups).  Here is a summary:\n",
    "\n",
    " - Randomly split the data into *k* folds\n",
    " - For *i* in 1...*k*, leave out fold *i* for testing\n",
    " - Train the classifier on all folds except for fold *i* (the left out fold)\n",
    " - Assess performance by testing on the left out fold *i*\n",
    " - Repeat and average performance across all folds\n",
    "\n",
    "Scikit-learn has built-in functions for creating CV folds and computing CV metrics.  An example is given below with the Perceptron neural network classifier.  Use this format on your own classifier to develop results for Week 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rare_Title</th>\n",
       "      <th>Sex_Female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.916454</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.859038</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.950608</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.733197</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.956649</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass      Fare   Age  Embarked_C  Embarked_S  Embarked_Q  \\\n",
       "0       0.0     3.0  0.916454  22.0         0.0         1.0         0.0   \n",
       "1       1.0     1.0  1.859038  38.0         1.0         0.0         0.0   \n",
       "2       1.0     3.0  0.950608  26.0         0.0         1.0         0.0   \n",
       "3       1.0     1.0  1.733197  35.0         0.0         1.0         0.0   \n",
       "4       0.0     3.0  0.956649  35.0         0.0         1.0         0.0   \n",
       "\n",
       "   Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Rare_Title  Sex_Female  \n",
       "0           0.0         0.0       1.0        0.0               0.0         0.0  \n",
       "1           0.0         0.0       0.0        1.0               0.0         1.0  \n",
       "2           0.0         1.0       0.0        0.0               0.0         1.0  \n",
       "3           0.0         0.0       0.0        1.0               0.0         1.0  \n",
       "4           0.0         0.0       1.0        0.0               0.0         0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "train_full = pd.read_csv('../data/train_complete.csv')\n",
    "\n",
    "# Drop the row indices\n",
    "train_full = train_full.drop(train_full.columns[0], axis=1)\n",
    "\n",
    "# Log transform the Fare feature to be more normally distributed\n",
    "train_full['Fare'] = np.log10(train_full['Fare'] + 1)\n",
    "\n",
    "train_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and std deviation of the CV scores is 0.691 (+/- 0.079)\n"
     ]
    }
   ],
   "source": [
    "# Ignore warnings from sklearn (omit this if you're still experimenting with code)\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "# Import the things we need for this code block\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Create the CV folds\n",
    "# First separate the target data from the features\n",
    "X = train_full.drop('Survived', axis=1)\n",
    "y = train_full['Survived']\n",
    "\n",
    "# Fit and sore the cross-validation using 10-fold CV\n",
    "classifier = Perceptron(random_state=154)\n",
    "scores = cross_val_score(classifier, X, y, cv=10)\n",
    "\n",
    "print('The mean and std deviation of the CV scores is {:.3f} (+/- {:.3f})'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of this Perceptron is 0.721\n",
      "\n",
      "\n",
      "Feature: \tCoefficient\n",
      "Pclass:\t-119.000\n",
      "Fare:\t154.698\n",
      "Age:\t-13.529\n",
      "Embarked_C:\t70.000\n",
      "Embarked_S:\t-30.000\n",
      "Embarked_Q:\t10.000\n",
      "Title_Master:\t55.000\n",
      "Title_Miss:\t101.000\n",
      "Title_Mr:\t-210.000\n",
      "Title_Mrs:\t112.000\n",
      "Title_Rare_Title:\t-4.000\n",
      "Sex_Female:\t225.000\n"
     ]
    }
   ],
   "source": [
    "# Examine the coefficients for each feature with a single fold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets (20% of the data for testing)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=154)\n",
    "\n",
    "# Train and score the classifier\n",
    "classifier2 = Perceptron(random_state=154)\n",
    "classifier2.fit(Xtrain, ytrain)\n",
    "scores2 = classifier2.score(Xtest, ytest)\n",
    "\n",
    "print('The score of this Perceptron is {:.3f}'.format(scores2))\n",
    "\n",
    "# Feature coefficients\n",
    "print('\\n\\nFeature: \\tCoefficient')\n",
    "for i, colname in enumerate(Xtrain.columns):\n",
    "    print('{}:\\t{:.3f}'.format(str(colname), float(classifier2.coef_[0][i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These Coefficients are Interpretable**\n",
    "\n",
    "Since this neural network has only one layer, we can interpret these coefficients as being positively or negatively related to the outcome (the absolute value isn't as interpretable, but relative values are).  It is clear that passenger class is inversely related to survival, fare positively related, and that being a woman or child is also positively related.  If we had used more than one layer, the coefficients would not be interpretable, which is a disadvantage of neural networks.\n",
    "\n",
    "**Not all Classifier Types have Coefficients**\n",
    "\n",
    "The Perceptron and some regression models will have coefficients that might indicate feature importance.  However, other models like RandomForest will have different ways of calculating feature importance.  See if you can google a way to do that for your particular model and ask questions on Slack if you need help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
